{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Car-GenuineSynthetic-Final-CapstoneZ.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPI01piwi5wJ",
        "outputId": "2f0233f2-88a9-4838-c8d6-aa7a7a31136e"
      },
      "source": [
        "#my imports\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "import pandas as pd\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CD_9jvIjDd9"
      },
      "source": [
        "#Github Links \n",
        "#Test Data\n",
        "negative_car_test = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_test.csv')\n",
        "positive_car_test = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_test.csv')\n",
        "total_car_test = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_test-2.csv')\n",
        "#Minimum Data\n",
        "negative_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_minimum.csv')\n",
        "positive_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_minimum.csv')\n",
        "total_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_minimum.csv')\n",
        "#Remainder Data\n",
        "negative_car_remainder = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_remainder.csv')\n",
        "positive_car_remainder = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_remainder.csv')\n",
        "total_car_remainder = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_remainder.csv')\n",
        "#Total Training Data\n",
        "master_negative_car_training = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/master_negative_car_training_final.csv')\n",
        "master_positive_car_training = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/master_positive_car_training_final.csv')\n",
        "total_master_training_final = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_master_training_final.csv')\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmyjWuTURBmz"
      },
      "source": [
        ""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "---icYu4jzcV"
      },
      "source": [
        "#Assigning Negative/Positive to copy\n",
        "negative_car_text = master_negative_car_training.copy()\n",
        "positive_car_text = master_positive_car_training.copy()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyi1Uc778fWW"
      },
      "source": [
        "#Positive and Negative Series for analysis\n",
        "negative_car_series = negative_car_text[\"text\"]\n",
        "positive_car_series = positive_car_text[\"text\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNwTbppgjPyN"
      },
      "source": [
        "#Making negative training series\n",
        "#negative_car_text.drop([\"rating\", \"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "#positive_car_text.drop([\"rating\", \"Unnamed: 0\"], axis = 1, inplace=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xs7m0KEClgo-"
      },
      "source": [
        "#negative_car_text.to_csv('negative_car.txt')\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FssPk0wu4Y0t"
      },
      "source": [
        "#positive_car_text.to_csv('positive_car.txt')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8p5Gqf-eASK"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jstkmmh8uYAX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "51082d21-96da-4f05-f12f-0030aad49563"
      },
      "source": [
        "#This is the code to get the text from GPT-2 to a Dataframe. neg_car_synthetic_df\n",
        "\"\"\"\n",
        "#POSITIVE DATAFRAME\n",
        "#COPY THE GPT FILE WITH DELIMETERS OF \" ^ \" \n",
        "#RUN THE FILE THROUGH THIS THE FOLLOWING FUNCTION\n",
        "#https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_working_final.txt\n",
        "def file_string():\n",
        "    with open(\"/content/positive_car_working_final.txt\",'r') as file:\n",
        "        lines = file.read()\n",
        "\n",
        "    return lines.replace('-\\n','').replace('\\n', ' ') \n",
        "\n",
        "new_file = (file_string())\n",
        "\n",
        "#Split the file\n",
        "big_break = new_file.split('^')\n",
        "\n",
        "#Create the lists to combine into a dataframe\n",
        "stars = []\n",
        "rating = []\n",
        "\n",
        "#Create the columns\n",
        "for x in big_break:\n",
        "  stars.append(2)\n",
        "  rating.append(\"positive\")\n",
        "\n",
        "#Make the dataframe\n",
        "my_dict = {\"rating\" : rating, 'text': big_break}\n",
        "pos_car_synthetic_df = pd.DataFrame(my_dict)\n",
        "\"\"\""
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#POSITIVE DATAFRAME\\n#COPY THE GPT FILE WITH DELIMETERS OF \" ^ \" \\n#RUN THE FILE THROUGH THIS THE FOLLOWING FUNCTION\\n#https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_working_final.txt\\ndef file_string():\\n    with open(\"/content/positive_car_working_final.txt\",\\'r\\') as file:\\n        lines = file.read()\\n\\n    return lines.replace(\\'-\\n\\',\\'\\').replace(\\'\\n\\', \\' \\') \\n\\nnew_file = (file_string())\\n\\n#Split the file\\nbig_break = new_file.split(\\'^\\')\\n\\n#Create the lists to combine into a dataframe\\nstars = []\\nrating = []\\n\\n#Create the columns\\nfor x in big_break:\\n  stars.append(2)\\n  rating.append(\"positive\")\\n\\n#Make the dataframe\\nmy_dict = {\"rating\" : rating, \\'text\\': big_break}\\npos_car_synthetic_df = pd.DataFrame(my_dict)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUva2LM7ebHe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ae2qhXfYu8sg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "54d59e94-d07b-436a-d1c9-6cc066f2f1f9"
      },
      "source": [
        "\n",
        "#This is the code to get the text from GPT-2 to a Dataframe. neg_car_synthetic_df\n",
        "\"\"\"\n",
        "#NEGATIVE DATAFRAME\n",
        "#COPY THE GPT FILE WITH DELIMETERS OF \" ^ \" \n",
        "#RUN THE FILE THROUGH THIS THE FOLLOWING FUNCTION\n",
        "#https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_final_working.txt\n",
        "def file_string():\n",
        "    with open(\"/content/negative_car_final_working.txt\",'r') as file:\n",
        "        lines = file.read()\n",
        "\n",
        "    return lines.replace('-\\n','').replace('\\n', ' ') \n",
        "\n",
        "new_file = (file_string())\n",
        "\n",
        "#Split the file\n",
        "big_break = new_file.split('^')\n",
        "\n",
        "#Create the lists to combine into a dataframe\n",
        "stars = []\n",
        "rating = []\n",
        "\n",
        "#Create the columns\n",
        "for x in big_break:\n",
        "  stars.append(2)\n",
        "  rating.append(\"negative\")\n",
        "\n",
        "#Make the dataframe\n",
        "my_dict = {\"rating\" : rating, 'text': big_break}\n",
        "neg_car_synthetic_df = pd.DataFrame(my_dict)\n",
        "\"\"\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n#NEGATIVE DATAFRAME\\n#COPY THE GPT FILE WITH DELIMETERS OF \" ^ \" \\n#RUN THE FILE THROUGH THIS THE FOLLOWING FUNCTION\\n#https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_final_working.txt\\ndef file_string():\\n    with open(\"/content/negative_car_final_working.txt\",\\'r\\') as file:\\n        lines = file.read()\\n\\n    return lines.replace(\\'-\\n\\',\\'\\').replace(\\'\\n\\', \\' \\') \\n\\nnew_file = (file_string())\\n\\n#Split the file\\nbig_break = new_file.split(\\'^\\')\\n\\n#Create the lists to combine into a dataframe\\nstars = []\\nrating = []\\n\\n#Create the columns\\nfor x in big_break:\\n  stars.append(2)\\n  rating.append(\"negative\")\\n\\n#Make the dataframe\\nmy_dict = {\"rating\" : rating, \\'text\\': big_break}\\nneg_car_synthetic_df = pd.DataFrame(my_dict)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aeeRFGiuX4b"
      },
      "source": [
        "#Negative Synthetic Data\n",
        "neg_car_synthetic_df = pd.read_csv(\"https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/capstone_synthetic_neg_car.csv\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piWuzAXhuxc7"
      },
      "source": [
        "#Positive Synthetic Data\n",
        "pos_car_synthetic_df = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/capstone_synthetic_pos_car.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKVLjTbmm0mV"
      },
      "source": [
        "#neg_car_synthetic_df.to_csv('capstone_synthetic_neg_car.csv')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8t2zMtV-DKg"
      },
      "source": [
        "#Shuffling dataframe\n",
        "neg_car_synthetic_df = neg_car_synthetic_df.sample(frac=1).reset_index(drop=True)\n",
        "pos_car_synthetic_df = pos_car_synthetic_df.sample(frac=1).reset_index(drop=True)\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP3uERvn_xaf"
      },
      "source": [
        "#Synthetic Data Broken Down\n",
        "#Pos_car = 6008\n",
        "#neg_car = 6044\n",
        "a_neg = neg_car_synthetic_df[1:500]\n",
        "a_pos = pos_car_synthetic_df[1:500]\n",
        "b_neg = neg_car_synthetic_df[501:1000]\n",
        "b_pos = pos_car_synthetic_df[501:1000]\n",
        "c_neg = neg_car_synthetic_df[1001:1500]\n",
        "c_pos = pos_car_synthetic_df[1001:1500]\n",
        "d_neg = neg_car_synthetic_df[1501:2000]\n",
        "d_pos = pos_car_synthetic_df[1501:2000]\n",
        "e_neg = neg_car_synthetic_df[2001:2500]\n",
        "e_pos = pos_car_synthetic_df[2001:2500]\n",
        "f_neg = neg_car_synthetic_df[2501:3000]\n",
        "f_pos = pos_car_synthetic_df[2501:3000]\n",
        "g_neg = neg_car_synthetic_df[3001:3500]\n",
        "g_pos = pos_car_synthetic_df[3001:3500]\n",
        "h_neg = neg_car_synthetic_df[3501:4000]\n",
        "h_pos = pos_car_synthetic_df[3501:4000]\n",
        "i_neg = neg_car_synthetic_df[4001:4500]\n",
        "i_pos = pos_car_synthetic_df[4001:4500]\n",
        "j_neg = neg_car_synthetic_df[4501:5000]\n",
        "j_pos = pos_car_synthetic_df[4501:5000]\n",
        "k_neg = neg_car_synthetic_df[5001:5500]\n",
        "k_pos = pos_car_synthetic_df[5001:5500]\n",
        "l_neg = neg_car_synthetic_df[5501:6008]\n",
        "l_pos = pos_car_synthetic_df[5501:6008]\n",
        "#2 thousand synthetic data\n",
        "a_two_thousand = pd.concat([a_neg,b_neg,c_neg,d_neg,a_pos,b_pos,c_pos,d_pos], axis = 0).reset_index(drop=True)\n",
        "b_two_thousand = pd.concat([e_neg,f_neg,g_neg,h_neg,e_pos,f_pos,g_pos,h_pos], axis = 0).reset_index(drop=True)\n",
        "c_two_thousand = pd.concat([i_neg,j_neg,k_neg,l_neg,i_pos,j_pos,k_pos,l_pos], axis = 0).reset_index(drop=True)\n",
        "#Full Synthetic Data\n",
        "all_synthetic_data = pd.concat([neg_car_synthetic_df, pos_car_synthetic_df], axis = 0).reset_index(drop=True)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1gv7AvBE10P"
      },
      "source": [
        "#Important Dataframes\n",
        "\n",
        "#Test Data Set\n",
        "total_car_test = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_test-2.csv')\n",
        "\n",
        "#Genuine Data Set Full\n",
        "total_master_training_final = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_master_training_final.csv')\n",
        "\n",
        "#Minimum Data Set\n",
        "total_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_minimum.csv')\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foIDBjlqHZeL"
      },
      "source": [
        "#test variables\n",
        "new_x_train, new_x_test, new_y_train, new_y_test = train_test_split(total_car_test['text'], total_car_test['rating'], random_state = 0, test_size = .991)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxYC5uuMfrDe"
      },
      "source": [
        "#GPT ONLY Double (Random)\n",
        "a_two_thousand = pd.concat([a_neg,b_neg,c_neg,d_neg,a_pos,b_pos,c_pos,d_pos], axis = 0).reset_index(drop=True)\n",
        "four_thousand_gpt = pd.concat([a_two_thousand, b_two_thousand], axis=0).reset_index(drop=True)\n",
        "six_thousand_gpt = pd.concat([a_two_thousand, b_two_thousand, c_two_thousand], axis=0).reset_index(drop=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKqTruxZJoIT"
      },
      "source": [
        "#Full Genuine and Full Synthetic\n",
        "synth_gen_full = pd.concat([total_master_training_final, all_synthetic_data], axis = 0).reset_index(drop=True)\n",
        "synth_gen_full.drop([\"Unnamed: 0\"], axis = 1, inplace=True)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQSzhimWhHN3"
      },
      "source": [
        "#Full Genuine with Level 1 Synthetic(2000)\n",
        "lv_one_gen_synth = pd.concat([total_master_training_final, a_two_thousand], axis = 0).reset_index(drop=True)\n",
        "lv_one_gen_synth.drop([\"Unnamed: 0\"], axis = 1, inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO7cwbkjGUY"
      },
      "source": [
        "#Full Genuine with Level 2 Synthetic(4000)\n",
        "lv_two_gen_synth = pd.concat([total_master_training_final, four_thousand_gpt], axis = 0).reset_index(drop=True)\n",
        "lv_two_gen_synth.drop([\"Unnamed: 0\"], axis = 1, inplace=True)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx2VE7ZGNsnr"
      },
      "source": [
        "#Minimum Genuine and Full Synthetic\n",
        "synth_gen_minimum = pd.concat([all_synthetic_data, total_car_minimum], axis = 0).reset_index(drop=True)\n",
        "synth_gen_minimum.drop([\"Unnamed: 0\"], axis = 1, inplace=True)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HdILS0QRLji"
      },
      "source": [
        "#Minimum Data\n",
        "negative_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/negative_car_minimum.csv')\n",
        "positive_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/positive_car_minimum.csv')\n",
        "total_car_minimum = pd.read_csv('https://raw.githubusercontent.com/success81/Synthetic_NLP_Data_Generation_Paper/main/Car_repair/total_car_minimum.csv')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJLAgEJSNQF"
      },
      "source": [
        "#Lite Genuine\n",
        "lite_neg = negative_car_minimum[1:51]\n",
        "lite_pos = positive_car_minimum[1:51]\n",
        "total_lite = pd.concat([lite_neg,lite_pos], axis = 0).reset_index(drop=True)\n",
        "total_lite.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#GPT ONLY\n",
        "a_two_thousand = pd.concat([a_neg,b_neg,c_neg,d_neg,a_pos,b_pos,c_pos,d_pos], axis = 0).reset_index(drop=True)\n",
        "b_two_thousand = pd.concat([e_neg,f_neg,g_neg,h_neg,e_pos,f_pos,g_pos,h_pos], axis = 0).reset_index(drop=True)\n",
        "c_two_thousand = pd.concat([i_neg,j_neg,k_neg,l_neg,i_pos,j_pos,k_pos,l_pos], axis = 0).reset_index(drop=True)\n",
        "\n",
        "#GPT ONLY Double\n",
        "a_two_thousand = pd.concat([a_neg,b_neg,c_neg,d_neg,a_pos,b_pos,c_pos,d_pos], axis = 0).reset_index(drop=True)\n",
        "four_thousand_gpt = pd.concat([a_two_thousand, b_two_thousand], axis=0).reset_index(drop=True)\n",
        "six_thousand_gpt = pd.concat([a_two_thousand, b_two_thousand, c_two_thousand], axis=0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "#GPT LITE MIX\n",
        "\n",
        "two_thousand_lite = pd.concat([a_two_thousand, total_lite], axis=0).reset_index(drop=True)\n",
        "four_thousand_lite = pd.concat([a_two_thousand, b_two_thousand, total_lite], axis=0).reset_index(drop=True)\n",
        "six_thousand_lite = pd.concat([a_two_thousand, b_two_thousand, c_two_thousand, total_lite], axis=0).reset_index(drop=True)\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrzV3kL-h40O"
      },
      "source": [
        "#Range of Cars Dataset\n",
        "#Car 1000\n",
        "scale_lv_1_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_1_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 2000\n",
        "scale_lv_2_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_2_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 3000\n",
        "scale_lv_3_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_3_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 4000\n",
        "scale_lv_4_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_4_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 5000\n",
        "scale_lv_5_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_5_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 6000\n",
        "scale_lv_6_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_6_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 7000\n",
        "scale_lv_7_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_7_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 8000\n",
        "scale_lv_8_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos, h_pos, h_neg], axis=0).reset_index(drop=True)\n",
        "scale_lv_8_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 9000\n",
        "scale_lv_9_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos, h_pos, h_neg, i_pos, i_neg], axis=0).reset_index(drop=True)\n",
        "scale_lv_9_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 10000\n",
        "scale_lv_10_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos, h_pos, h_neg,i_pos, i_neg, j_neg, j_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_10_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 11000\n",
        "scale_lv_11_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos, h_pos, h_neg,i_pos, i_neg, j_neg, j_pos, k_neg, k_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_11_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "#Car 12000\n",
        "scale_lv_12_gen_syn = pd.concat([total_master_training_final, a_neg, a_pos, b_neg, b_pos, c_neg, c_pos, d_neg, d_pos, e_neg, e_pos, f_neg, f_pos, g_neg, g_pos, h_pos, h_neg,i_pos, i_neg, j_neg, j_pos, k_neg, k_pos, l_neg, l_pos], axis=0).reset_index(drop=True)\n",
        "scale_lv_12_gen_syn.drop([\"Unnamed: 0\"], axis = 1, inplace=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "Bt7e8bnSm2L_",
        "outputId": "44f4028e-3e72-45b3-fa1c-6934c7e06fc0"
      },
      "source": [
        "# check for missing values\n",
        "display(synth_gen_full.isna().any())\n",
        " \n",
        "# drop any missing values\n",
        "synth_gen_full = synth_gen_full.dropna()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "rating    False\n",
              "text      True \n",
              "dtype: bool"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RFbEdX3qXGR"
      },
      "source": [
        "### ***Model Testing Bayes***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuQZJ1vgCpq1"
      },
      "source": [
        "#This is the Training of the Genuine and Synthetic Naive Bayes Model For Car Reviews\n",
        "x_train, x_test, y_train, y_test = train_test_split(synth_gen_full['text'], synth_gen_full['rating'], random_state = 0)\n",
        "count_vect = CountVectorizer()\n",
        "x_train_counts = count_vect.fit_transform(x_train)\n",
        "tfidf_transformer = TfidfTransformer()\n",
        "x_train_tfidf = tfidf_transformer.fit_transform(x_train_counts)\n",
        "clf = MultinomialNB().fit(x_train_tfidf, y_train)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9DoBNvRGWA3"
      },
      "source": [
        "#New Predict\n",
        "naive_bayes_predict = clf.predict(count_vect.transform(new_x_test))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD_KFvJUGmnh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b12579-68dc-4a1a-be65-c14b0b1f66f3"
      },
      "source": [
        "#Precision Score\n",
        "precision_score(new_y_test, naive_bayes_predict, average=\"weighted\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9036087369420703"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e2nUGRYGxVR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a874a5cd-fdc3-445a-9a4f-2f3c72c51744"
      },
      "source": [
        "#accuracy_score\n",
        "accuracy_score(new_y_test, naive_bayes_predict)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8803418803418803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPcq8FvvG2Wd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0b02493-553f-4f19-fd71-b9486137fdd8"
      },
      "source": [
        "#Recall Score\n",
        "recall_score(new_y_test, naive_bayes_predict, average=\"weighted\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8803418803418803"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G30QDhaMHDCC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eca920f8-df41-4642-92e4-7e42c28e2da8"
      },
      "source": [
        "#F1\n",
        "f1_score(new_y_test, naive_bayes_predict, average=\"weighted\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8787310979618672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbN_BMDQHELq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08fe0c5d-3d95-4eb1-d0a6-df1d1b4d54f2"
      },
      "source": [
        "#Confusion Matrix\n",
        "cm = confusion_matrix(new_y_test, naive_bayes_predict)\n",
        "print (cm)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[58  0]\n",
            " [14 45]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g23CM6lqSJMT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "1a06600e-c9eb-4720-b2cf-48d33c461908"
      },
      "source": [
        "#Scores for Range chart 4 features. I am adding 1000 synthetic datapoints to the genuine data\n",
        "\n",
        "\"\"\"\n",
        "Level 0 NO SYNTHETIC DATA\n",
        "-Precision: 0.8202310510002817\n",
        "-Accuracy: 0.717948717948718\n",
        "-Recall: 0.717948717948718\n",
        "-F1: 0.6944314535313351\n",
        "\n",
        "Level 1 1000 synthetic data boost\n",
        "-Precision: 0.8682246024018175\n",
        "-Accuracy: 0.8205128205128205\n",
        "-Recall: 0.8205128205128205\n",
        "-F1: 0.8148401126051814\n",
        "\n",
        "Level 2 2000 synthetic data boost\n",
        "-Precision: 0.8776778776778777\n",
        "-Accuracy: 0.8376068376068376\n",
        "-Recall: 0.8376068376068376\n",
        "-F1: 0.8334513223402112\n",
        "\n",
        "Level 3 3000 synthetic data boost\n",
        "-Precision: 0.8876353276353276\n",
        "-Accuracy: 0.8547008547008547\n",
        "-Recall: 0.8547008547008547\n",
        "-F1: 0.8517587444111675\n",
        "\n",
        "\n",
        "Level 4 4000 synthetic data boost\n",
        "-Precision: 0.8876353276353276\n",
        "-Accuracy: 0.8547008547008547\n",
        "-Recall: 0.8547008547008547\n",
        "-F1: 0.8517587444111675\n",
        "\n",
        "Level 5 5000 synthetic data boost\n",
        "-Precision: 0.9092331768388107\n",
        "-Accuracy: 0.8888888888888888\n",
        "-Recall: 0.8888888888888888\n",
        "-F1: 0.8876092038882736\n",
        "\n",
        "Level 6 6000 synthetic data boost\n",
        "-Precision: 0.8981383912890762\n",
        "-Accuracy: 0.8888888888888888\n",
        "-Recall: 0.8888888888888888\n",
        "-F1: 0.8876092038882736\n",
        "\n",
        "Level 7 7000 synthetic data boost\n",
        "-Precision: 0.8912886460345126\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Level 8 8000 synthetic data boost\n",
        "-Precision: 0.9032809983896939\n",
        "-Accuracy: 0.8888888888888888\n",
        "-Recall: 0.8888888888888888\n",
        "-F1: 0.8879894686061439\n",
        "\n",
        "Level 9 9000 synthetic data boost\n",
        "-Precision: 0.9036087369420703\n",
        "-Accuracy: 0.8803418803418803\n",
        "-Recall: 0.8803418803418803\n",
        "-F1: 0.8787310979618672\n",
        "\n",
        "Level 10 10000 synthetic data boost\n",
        "-Precision: 0.8876353276353276\n",
        "-Accuracy: 0.8547008547008547\n",
        "-Recall: 0.8547008547008547\n",
        "-F1: 0.8517587444111675\n",
        "\n",
        "Level 11 11000 synthetic data boost\n",
        "-Precision: 0.915018315018315\n",
        "-Accuracy: 0.8974358974358975\n",
        "-Recall: 0.8974358974358975\n",
        "-F1: 0.8964380745041122\n",
        "\n",
        "Level 12 12000 synthetic data boost\n",
        "-Precision: 0.9032809983896939\n",
        "-Accuracy: 0.8888888888888888\n",
        "-Recall: 0.8888888888888888\n",
        "-F1: 0.8879894686061439\n",
        "\"\"\"\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nLevel 0 NO SYNTHETIC DATA\\n-Precision: 0.8202310510002817\\n-Accuracy: 0.717948717948718\\n-Recall: 0.717948717948718\\n-F1: 0.6944314535313351\\n\\nLevel 1 1000 synthetic data boost\\n-Precision: 0.8682246024018175\\n-Accuracy: 0.8205128205128205\\n-Recall: 0.8205128205128205\\n-F1: 0.8148401126051814\\n\\nLevel 2 2000 synthetic data boost\\n-Precision: 0.8776778776778777\\n-Accuracy: 0.8376068376068376\\n-Recall: 0.8376068376068376\\n-F1: 0.8334513223402112\\n\\nLevel 3 3000 synthetic data boost\\n-Precision: 0.8876353276353276\\n-Accuracy: 0.8547008547008547\\n-Recall: 0.8547008547008547\\n-F1: 0.8517587444111675\\n\\n\\nLevel 4 4000 synthetic data boost\\n-Precision: 0.8876353276353276\\n-Accuracy: 0.8547008547008547\\n-Recall: 0.8547008547008547\\n-F1: 0.8517587444111675\\n\\nLevel 5 5000 synthetic data boost\\n-Precision: 0.9092331768388107\\n-Accuracy: 0.8888888888888888\\n-Recall: 0.8888888888888888\\n-F1: 0.8876092038882736\\n\\nLevel 6 6000 synthetic data boost\\n-Precision: 0.8981383912890762\\n-Accuracy: 0.8888888888888888\\n-Recall: 0.8888888888888888\\n-F1: 0.8876092038882736\\n\\nLevel 7 7000 synthetic data boost\\n-Precision: 0.8912886460345126\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nLevel 8 8000 synthetic data boost\\n-Precision: 0.9032809983896939\\n-Accuracy: 0.8888888888888888\\n-Recall: 0.8888888888888888\\n-F1: 0.8879894686061439\\n\\nLevel 9 9000 synthetic data boost\\n-Precision: 0.9036087369420703\\n-Accuracy: 0.8803418803418803\\n-Recall: 0.8803418803418803\\n-F1: 0.8787310979618672\\n\\nLevel 10 10000 synthetic data boost\\n-Precision: 0.8876353276353276\\n-Accuracy: 0.8547008547008547\\n-Recall: 0.8547008547008547\\n-F1: 0.8517587444111675\\n\\nLevel 11 11000 synthetic data boost\\n-Precision: 0.915018315018315\\n-Accuracy: 0.8974358974358975\\n-Recall: 0.8974358974358975\\n-F1: 0.8964380745041122\\n\\nLevel 12 12000 synthetic data boost\\n-Precision: 0.9032809983896939\\n-Accuracy: 0.8888888888888888\\n-Recall: 0.8888888888888888\\n-F1: 0.8879894686061439\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FOqLFfiI9tJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "outputId": "793e55ed-3210-4802-e8a2-85855cf3c6d0"
      },
      "source": [
        "\"\"\"\n",
        "Scores\n",
        "#####THis is the experiment showing an 80< model getting data added to it\n",
        "Genuine only\n",
        "-Precision: 0.8202310510002817\n",
        "-Accuaracy: 0.717948717948718\n",
        "-Recall: 0.717948717948718\n",
        "-F1: 0.6944314535313351\n",
        "\n",
        "Genuine with Level 1 (2000 sythetic)\n",
        "-Precision: 0.9036087369420703\n",
        "-Accuracy: 0.8803418803418803\n",
        "-Recall: 0.8803418803418803\n",
        "-F1: 0.8787310979618672\n",
        "\n",
        "Genuine with Level 2 (4000 Synthetic)\n",
        "-Precision: 0.9036087369420703\n",
        "-Accuracy: 0.8803418803418803\n",
        "-Recall: 0.8803418803418803\n",
        "-F1: 0.8787310979618672\n",
        "\n",
        "\n",
        "\n",
        "Genuine with Full Synthetic\n",
        "-Precision: 0.9036087369420703\n",
        "-Accuaracy: 0.8803418803418803\n",
        "-Recall: 0.8803418803418803\n",
        "-F1: 0.8787310979618672\n",
        "\n",
        "#####This is an alternative experiment showing limited data and synthetic\n",
        "Genuine only minimum dataset\n",
        "-Precision: 0.8101472995090017\n",
        "-Accuracy: 0.6923076923076923\n",
        "-Recall: 0.6923076923076923\n",
        "-F1: 0.6612027253875776\n",
        "\n",
        "Genuine Minimum with Synthetic\n",
        "-Precision: 0.915018315018315\n",
        "-Accuracy: 0.8974358974358975\n",
        "-Recall: 0.8974358974358975\n",
        "-F1: 0.8964380745041122\n",
        "\n",
        "#####This is an experiment to show super limited data gradually augmented with Synthetic Data\n",
        "Lite (50 observations)\n",
        "-Precision: 0.788948125581789\n",
        "-Accuracy: 0.6324786324786325\n",
        "-Recall: 0.6324786324786325\n",
        "-F1: 0.5768187926678493\n",
        "\n",
        "Synthetic Alone Level 1\n",
        "-Precision: 0.8912886460345126\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Synthetic Alone Level 2\n",
        "-Precision: 0.8912886460345126\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Synthetic Alone Level 3\n",
        "-Precision: 0.8855908584169455\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Synthetic / Mix Level 1\n",
        "-Precision: 0.8912886460345126\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Synthetic / Mix Level 2\n",
        "-Precision: 0.8912886460345126\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8703183121787773\n",
        "\n",
        "Synthetic / Mix Level 3\n",
        "-Precision: 0.8855908584169455\n",
        "-Accuracy: 0.8717948717948718\n",
        "-Recall: 0.8717948717948718\n",
        "-F1: 0.8707570791609354\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nScores\\n#####THis is the experiment showing an 80< model getting data added to it\\nGenuine only\\n-Precision: 0.8202310510002817\\n-Accuaracy: 0.717948717948718\\n-Recall: 0.717948717948718\\n-F1: 0.6944314535313351\\n\\nGenuine with Level 1 (2000 sythetic)\\n-Precision: 0.9036087369420703\\n-Accuracy: 0.8803418803418803\\n-Recall: 0.8803418803418803\\n-F1: 0.8787310979618672\\n\\nGenuine with Level 2 (4000 Synthetic)\\n-Precision: 0.9036087369420703\\n-Accuracy: 0.8803418803418803\\n-Recall: 0.8803418803418803\\n-F1: 0.8787310979618672\\n\\n\\n\\nGenuine with Full Synthetic\\n-Precision: 0.9036087369420703\\n-Accuaracy: 0.8803418803418803\\n-Recall: 0.8803418803418803\\n-F1: 0.8787310979618672\\n\\n#####This is an alternative experiment showing limited data and synthetic\\nGenuine only minimum dataset\\n-Precision: 0.8101472995090017\\n-Accuracy: 0.6923076923076923\\n-Recall: 0.6923076923076923\\n-F1: 0.6612027253875776\\n\\nGenuine Minimum with Synthetic\\n-Precision: 0.915018315018315\\n-Accuracy: 0.8974358974358975\\n-Recall: 0.8974358974358975\\n-F1: 0.8964380745041122\\n\\n#####This is an experiment to show super limited data gradually augmented with Synthetic Data\\nLite (50 observations)\\n-Precision: 0.788948125581789\\n-Accuracy: 0.6324786324786325\\n-Recall: 0.6324786324786325\\n-F1: 0.5768187926678493\\n\\nSynthetic Alone Level 1\\n-Precision: 0.8912886460345126\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nSynthetic Alone Level 2\\n-Precision: 0.8912886460345126\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nSynthetic Alone Level 3\\n-Precision: 0.8855908584169455\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nSynthetic / Mix Level 1\\n-Precision: 0.8912886460345126\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nSynthetic / Mix Level 2\\n-Precision: 0.8912886460345126\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8703183121787773\\n\\nSynthetic / Mix Level 3\\n-Precision: 0.8855908584169455\\n-Accuracy: 0.8717948717948718\\n-Recall: 0.8717948717948718\\n-F1: 0.8707570791609354\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}