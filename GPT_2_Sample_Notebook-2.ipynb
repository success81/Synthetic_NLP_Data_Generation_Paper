{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT-2 Sample Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZWwktqDYwaM",
        "outputId": "9fc4b0c6-72ed-43ee-abb1-4f87f0be0093"
      },
      "source": [
        "#my imports\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize\n",
        "import string\n",
        "from nltk import pos_tag\n",
        "import pandas as pd\n",
        "from nltk import pos_tag\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:13: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  del sys.path[0]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-lKKMPMHYSp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9297b76-408f-4c74-8453-83bb218b61cb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z51hrNA9ASv6"
      },
      "source": [
        "### **GPT-2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCZ7m3s58u62"
      },
      "source": [
        "high_pizza_link = \"/content/n_high_pizza_positive.txt\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbITurSWAdJe",
        "outputId": "2c3201af-7530-428b-d7c3-b234fc19e3e8"
      },
      "source": [
        "GPT-Install\n",
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "gpt2.download_gpt2(model_name=\"355M\")\n",
        "\n",
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 395Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 130Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 591Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 1.42Git [00:05, 250Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 330Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 128Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 197Mit/s]                                                       "
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ify1Y7suIyyY"
      },
      "source": [
        "#Command to generate text GPT-2\n",
        "gpt2.generate(sess, run_name = \"low-1\", length=70, temperature=.9, prefix=\"The crust was really tasty\", nsamples=25, batch_size=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G3cwPx2ASUS"
      },
      "source": [
        "#GPT2 Model\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=high_pizza_link,\n",
        "              model_name='355M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='low-1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cf6CA_NXZmBf"
      },
      "source": [
        "### **PIZZA PROJECT**\n"
      ]
    }
  ]
}